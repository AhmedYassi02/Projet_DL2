{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from principal_DBN_alpha import *\n",
    "from principal_RBM_alpha import *\n",
    "from utils import *\n",
    "from tqdm import tqdm, notebook\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etude sur Binary AlphaDigit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = lire_alpha_digit(caracs, path_data=path_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On entraine un RBM sur les données de Binary AlphaDigit puis on genere des images à partir de ce qu'il a appris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = 200\n",
    "epochs = 200\n",
    "nb_pixels = 20*16\n",
    "learning_rate = 0.1\n",
    "gibbs_steps = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On entraine un RBM pour chaque caractère."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_rbm_caracs = []\n",
    "for carac in notebook.tqdm(list(caracs.keys()), desc=\"Characters\", unit=\"char\", leave=False):\n",
    "    data = lire_alpha_digit([carac], path_data)\n",
    "    nb_pixels = data.shape[1]\n",
    "    rbm = RBM(p = nb_pixels, q = neurons)\n",
    "    rbm.train_RBM(x=data, epochs=epochs, lr=learning_rate, show_progress=True)\n",
    "    list_rbm_caracs.append(rbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On genere des images des caractères en utilisant la méthode de Gibbs Sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 9, figsize=(10, 7), sharex=True, sharey=True)\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i, rbm in enumerate(list_rbm_caracs):\n",
    "    img = rbm.generer_image_RBM(gibbs_steps, 1)  # 1 image with 100 Gibbs steps\n",
    "    \n",
    "    img_reshaped = img[0].cpu().reshape(20, 16)\n",
    "    \n",
    "    axs[i].imshow(img_reshaped, cmap='Greys')\n",
    "    axs[i].set_title(list(caracs.keys())[i])\n",
    "    axs[i].axis('off')\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "# plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_dbn_caracs = []\n",
    "for carac in notebook.tqdm(list(caracs.keys()), desc=\"Characters\", unit=\"char\", leave=True):\n",
    "            data = lire_alpha_digit([carac], path_data)     \n",
    "            nb_pixels = data.shape[1]\n",
    "            # les couches du dbn (de chaque rbm en soit)\n",
    "            layers = [nb_pixels, neurons, neurons, neurons]\n",
    "\n",
    "            dbn = DBN(layers=layers)\n",
    "            dbn.train_DBN(x=data, epochs=[epochs], lr=learning_rate, plot=False, show_progress=True)\n",
    "            liste_dbn_caracs.append(dbn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 9, figsize=(10, 7), sharex=True, sharey=True)\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i, dbn in enumerate(liste_dbn_caracs):\n",
    "    img = dbn.generer_image_DBN(gibbs_steps, 1)  # 1 image with 100 Gibbs steps\n",
    "    \n",
    "    img_reshaped = img[0].cpu().reshape(20, 16)\n",
    "    \n",
    "    axs[i].imshow(img_reshaped, cmap='Greys')\n",
    "    axs[i].set_title(list(caracs.keys())[i])\n",
    "    axs[i].axis('off')\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Étude sur MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données MNIST et processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from principal_DNN_MNIST import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "# if not exist, download mnist dataset\n",
    "train_set = torchvision.datasets.MNIST(root='./data', train=True, transform=None, download=True)\n",
    "test_set = torchvision.datasets.MNIST(root='./data', train=False, transform=None, download=True)\n",
    "batch_size = 100\n",
    "\n",
    "train_set.data = (train_set.data > 127).float()\n",
    "test_set.data = (test_set.data > 127).float()\n",
    "\n",
    "\n",
    "# Applatir les images (28*28) en vecteurs (784)\n",
    "train_mnist = train_set.data.view(train_set.data.shape[0], -1).double().to(device)\n",
    "test_mnist = test_set.data.view(test_set.data.shape[0], -1).double().to(device) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 784]),\n",
       " torch.Size([60000, 10]),\n",
       " torch.Size([10000, 784]),\n",
       " torch.Size([10000, 10]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One Hot Encoding des labels\n",
    "labels_train_mnist = torch.nn.functional.one_hot(train_set.targets).float().to(device)\n",
    "labels_test_mnist = torch.nn.functional.one_hot(test_set.targets).float().to(device)\n",
    "\n",
    "\n",
    "train_mnist.shape, labels_train_mnist.shape, test_mnist.shape, labels_test_mnist.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test du DNN sur MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nb_pixels = train_mnist.shape[1]\n",
    "neurons = 200\n",
    "epochs = 200\n",
    "learning_rate = 0.2\n",
    "layers_dbn = [nb_pixels, neurons, neurons, neurons]\n",
    "nb_classes = len(train_set.class_to_idx)\n",
    "batch_size = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN pre-entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training DBN: 100%|██████████| 3/3 [09:18<00:00, 186.09s/RBM]\n"
     ]
    }
   ],
   "source": [
    "dnn_pretrain = DNN(layers_dbn, nb_classes=nb_classes)\n",
    "dnn_pretrain.pretrain_DNN(x=train_mnist, epochs=[epochs], lr=learning_rate, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation sur 2 DNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non pré-entrainé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training DNN: 100%|██████████| 200/200 [05:14<00:00,  1.57s/epoch, Loss=0.182] \n"
     ]
    }
   ],
   "source": [
    "dnn_non_pretrain = DNN(layers_dbn, nb_classes=nb_classes)\n",
    "dnn_non_pretrain.retropropagation(X=train_mnist, Y=labels_train_mnist, epochs=epochs, lr=learning_rate, batch_size=batch_size, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-entrainé "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training DNN: 100%|██████████| 200/200 [05:12<00:00,  1.56s/epoch, Loss=0.0855]\n"
     ]
    }
   ],
   "source": [
    "dnn_pretrain.retropropagation(X=train_mnist, Y=labels_train_mnist, epochs=epochs, lr=learning_rate,batch_size=batch_size, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test des deux DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taux d'erreur = 0.04280000180006027\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.0428),\n",
       " tensor([[3.8927e-11, 5.0956e-11, 1.6646e-08,  ..., 1.0000e+00, 5.5229e-13,\n",
       "          6.2407e-09],\n",
       "         [1.0738e-09, 3.9581e-06, 1.0000e+00,  ..., 4.4147e-09, 5.1350e-08,\n",
       "          3.6345e-14],\n",
       "         [1.7822e-11, 9.9998e-01, 3.0964e-11,  ..., 2.2638e-05, 2.7290e-10,\n",
       "          4.3201e-11],\n",
       "         ...,\n",
       "         [7.6290e-10, 3.6564e-10, 1.3343e-12,  ..., 6.8163e-08, 2.1116e-06,\n",
       "          2.4690e-06],\n",
       "         [1.2324e-06, 3.5321e-08, 4.3387e-10,  ..., 7.0744e-10, 2.0673e-03,\n",
       "          7.0958e-09],\n",
       "         [2.7588e-08, 7.9022e-08, 1.1453e-07,  ..., 6.8338e-11, 1.3528e-09,\n",
       "          9.0773e-09]], dtype=torch.float64))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_pretrain.test_DNN(test_mnist, labels_test_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taux d'erreur = 0.05770000070333481\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.0577),\n",
       " tensor([[6.0626e-08, 5.1642e-06, 1.4155e-03,  ..., 9.9843e-01, 1.7809e-07,\n",
       "          1.0193e-05],\n",
       "         [4.2668e-06, 2.1676e-04, 9.9880e-01,  ..., 5.8320e-05, 9.4321e-05,\n",
       "          2.7142e-08],\n",
       "         [5.0941e-09, 9.9997e-01, 4.1112e-07,  ..., 2.1902e-05, 6.9400e-07,\n",
       "          1.2637e-07],\n",
       "         ...,\n",
       "         [5.2074e-05, 4.2364e-05, 2.0049e-03,  ..., 4.1218e-04, 2.0926e-04,\n",
       "          4.6185e-04],\n",
       "         [6.4549e-05, 4.8565e-03, 4.7160e-05,  ..., 6.6344e-06, 1.9525e-03,\n",
       "          5.1822e-07],\n",
       "         [9.4118e-05, 6.1847e-08, 3.9474e-06,  ..., 1.9364e-08, 5.8551e-06,\n",
       "          5.1855e-08]], dtype=torch.float64))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_non_pretrain.test_DNN(test_mnist, labels_test_mnist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from principal_DNN_MNIST import *\n",
    "# import torchvision.datasets\n",
    "# # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "# # if not exist, download mnist dataset\n",
    "# train_set = torchvision.datasets.MNIST(root='./data', train=True, transform=None, download=True)\n",
    "# test_set = torchvision.datasets.MNIST(root='./data', train=False, transform=None, download=True)\n",
    "# batch_size = 100\n",
    "\n",
    "# train_set.data = (train_set.data > 127).float()\n",
    "# test_set.data = (test_set.data > 127).float()\n",
    "\n",
    "\n",
    "# # Applatir les images (28*28) en vecteurs (784)\n",
    "# train_mnist = train_set.data.view(train_set.data.shape[0], -1).double().to(device)\n",
    "# test_mnist = test_set.data.view(test_set.data.shape[0], -1).double().to(device) \n",
    "\n",
    "# # One Hot Encoding des labels\n",
    "# labels_train_mnist = torch.nn.functional.one_hot(train_set.targets).float().to(device)\n",
    "# labels_test_mnist = torch.nn.functional.one_hot(test_set.targets).float().to(device)\n",
    "\n",
    "\n",
    "# train_mnist.shape, labels_train_mnist.shape, test_mnist.shape, labels_test_mnist.shape\n",
    "\n",
    "# ## Test du DNN sur MNIST\n",
    "# nb_pixels = train_mnist.shape[1]\n",
    "# neurons = 200\n",
    "# epochs = 200\n",
    "# learning_rate = 0.1\n",
    "# layers_dbn = [nb_pixels, neurons, neurons, neurons]\n",
    "# nb_classes = len(train_set.class_to_idx)\n",
    "\n",
    "# ### Backpropagation sur 2 DNN\n",
    "\n",
    "# torch.unique(train_set.targets)\n",
    "# dnn_non_pretrain = DNN(layers_dbn, nb_classes=nb_classes)\n",
    "# dnn_non_pretrain.retropropagation(X=train_mnist, Y=labels_train_mnist, epochs=epochs, lr=learning_rate, show_progress=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
