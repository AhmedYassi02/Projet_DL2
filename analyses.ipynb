{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from principal_DBN_alpha import *\n",
    "from principal_RBM_alpha import *\n",
    "from utils import *\n",
    "from tqdm import tqdm, notebook\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etude sur Binary AlphaDigit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = lire_alpha_digit(caracs, path_data=path_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On entraine un RBM sur les données de Binary AlphaDigit puis on genere des images à partir de ce qu'il a appris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = 200\n",
    "epochs = 200\n",
    "nb_pixels = 20*16\n",
    "learning_rate = 0.1\n",
    "gibbs_steps = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On entraine un RBM pour chaque caractère."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_rbm_caracs = []\n",
    "for carac in notebook.tqdm(list(caracs.keys()), desc=\"Characters\", unit=\"char\", leave=False):\n",
    "    data = lire_alpha_digit([carac], path_data)\n",
    "    nb_pixels = data.shape[1]\n",
    "    rbm = RBM(p = nb_pixels, q = neurons)\n",
    "    rbm.train_RBM(x=data, epochs=epochs, lr=learning_rate, show_progress=True)\n",
    "    list_rbm_caracs.append(rbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On genere des images des caractères en utilisant la méthode de Gibbs Sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 9, figsize=(10, 7), sharex=True, sharey=True)\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i, rbm in enumerate(list_rbm_caracs):\n",
    "    img = rbm.generer_image_RBM(gibbs_steps, 1)  # 1 image with 100 Gibbs steps\n",
    "    \n",
    "    img_reshaped = img[0].cpu().reshape(20, 16)\n",
    "    \n",
    "    axs[i].imshow(img_reshaped, cmap='Greys')\n",
    "    axs[i].set_title(list(caracs.keys())[i])\n",
    "    axs[i].axis('off')\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "# plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_dbn_caracs = []\n",
    "for carac in notebook.tqdm(list(caracs.keys()), desc=\"Characters\", unit=\"char\", leave=True):\n",
    "            data = lire_alpha_digit([carac], path_data)     \n",
    "            nb_pixels = data.shape[1]\n",
    "            # les couches du dbn (de chaque rbm en soit)\n",
    "            layers = [nb_pixels, neurons, neurons, neurons]\n",
    "\n",
    "            dbn = DBN(layers=layers)\n",
    "            dbn.train_DBN(x=data, epochs=[epochs], lr=learning_rate, plot=False, show_progress=True)\n",
    "            liste_dbn_caracs.append(dbn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 9, figsize=(10, 7), sharex=True, sharey=True)\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i, dbn in enumerate(liste_dbn_caracs):\n",
    "    img = dbn.generer_image_DBN(gibbs_steps, 1)  # 1 image with 100 Gibbs steps\n",
    "    \n",
    "    img_reshaped = img[0].cpu().reshape(20, 16)\n",
    "    \n",
    "    axs[i].imshow(img_reshaped, cmap='Greys')\n",
    "    axs[i].set_title(list(caracs.keys())[i])\n",
    "    axs[i].axis('off')\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Étude sur MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données MNIST et processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from principal_DNN_MNIST import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "# if not exist, download mnist dataset\n",
    "train_set = torchvision.datasets.MNIST(root='./data', train=True, transform=None, download=True)\n",
    "test_set = torchvision.datasets.MNIST(root='./data', train=False, transform=None, download=True)\n",
    "batch_size = 100\n",
    "\n",
    "train_set.data = (train_set.data > 127).float()\n",
    "test_set.data = (test_set.data > 127).float()\n",
    "\n",
    "\n",
    "# Applatir les images (28*28) en vecteurs (784)\n",
    "train_mnist = train_set.data.view(train_set.data.shape[0], -1).double().to(device)\n",
    "test_mnist = test_set.data.view(test_set.data.shape[0], -1).double().to(device) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 784]),\n",
       " torch.Size([60000, 10]),\n",
       " torch.Size([10000, 784]),\n",
       " torch.Size([10000, 10]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One Hot Encoding des labels\n",
    "labels_train_mnist = torch.nn.functional.one_hot(train_set.targets).float().to(device)\n",
    "labels_test_mnist = torch.nn.functional.one_hot(test_set.targets).float().to(device)\n",
    "\n",
    "\n",
    "train_mnist.shape, labels_train_mnist.shape, test_mnist.shape, labels_test_mnist.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test du DNN sur MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nb_pixels = train_mnist.shape[1]\n",
    "neurons = 200\n",
    "epochs = 200\n",
    "learning_rate = 0.2\n",
    "layers_dbn = [nb_pixels, neurons, neurons, neurons]\n",
    "nb_classes = len(train_set.class_to_idx)\n",
    "batch_size = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN pre-entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training DBN:   0%|          | 0/3 [00:00<?, ?RBM/s]"
     ]
    }
   ],
   "source": [
    "dnn_pretrain = DNN(layers_dbn, nb_classes=nb_classes)\n",
    "dnn_pretrain.pretrain_DNN(x=train_mnist, epochs=[epochs], lr=learning_rate, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation sur 2 DNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-entrainé "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_pretrain.retropropagation(X=train_mnist, Y=labels_train_mnist, epochs=epochs, lr=learning_rate,batch_size=batch_size, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non pré-entrainé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_non_pretrain = DNN(layers_dbn, nb_classes=nb_classes)\n",
    "dnn_non_pretrain.retropropagation(X=train_mnist, Y=labels_train_mnist, epochs=epochs, lr=learning_rate, batch_size=batch_size, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test des deux DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_pretrain.test_DNN(test_mnist, labels_test_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_non_pretrain.test_DNN(test_mnist, labels_test_mnist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from principal_DNN_MNIST import *\n",
    "# import torchvision.datasets\n",
    "# # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "# # if not exist, download mnist dataset\n",
    "# train_set = torchvision.datasets.MNIST(root='./data', train=True, transform=None, download=True)\n",
    "# test_set = torchvision.datasets.MNIST(root='./data', train=False, transform=None, download=True)\n",
    "# batch_size = 100\n",
    "\n",
    "# train_set.data = (train_set.data > 127).float()\n",
    "# test_set.data = (test_set.data > 127).float()\n",
    "\n",
    "\n",
    "# # Applatir les images (28*28) en vecteurs (784)\n",
    "# train_mnist = train_set.data.view(train_set.data.shape[0], -1).double().to(device)\n",
    "# test_mnist = test_set.data.view(test_set.data.shape[0], -1).double().to(device) \n",
    "\n",
    "# # One Hot Encoding des labels\n",
    "# labels_train_mnist = torch.nn.functional.one_hot(train_set.targets).float().to(device)\n",
    "# labels_test_mnist = torch.nn.functional.one_hot(test_set.targets).float().to(device)\n",
    "\n",
    "\n",
    "# train_mnist.shape, labels_train_mnist.shape, test_mnist.shape, labels_test_mnist.shape\n",
    "\n",
    "# ## Test du DNN sur MNIST\n",
    "# nb_pixels = train_mnist.shape[1]\n",
    "# neurons = 200\n",
    "# epochs = 200\n",
    "# learning_rate = 0.1\n",
    "# layers_dbn = [nb_pixels, neurons, neurons, neurons]\n",
    "# nb_classes = len(train_set.class_to_idx)\n",
    "\n",
    "# ### Backpropagation sur 2 DNN\n",
    "\n",
    "# torch.unique(train_set.targets)\n",
    "# dnn_non_pretrain = DNN(layers_dbn, nb_classes=nb_classes)\n",
    "# dnn_non_pretrain.retropropagation(X=train_mnist, Y=labels_train_mnist, epochs=epochs, lr=learning_rate, show_progress=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
